{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8efca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc30f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for Langsmith tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b688c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001E384E8A980> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E384E8A290> root_client=<openai.OpenAI object at 0x000001E384DB4790> root_async_client=<openai.AsyncOpenAI object at 0x000001E384E8AB60> model_name='gpt-4o-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39697429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a class of artificial intelligence techniques that focus on creating new content, whether that be text, images, music, or other media, based on learned patterns from existing data. Unlike traditional AI, which might classify or analyze datasets, generative AI can produce new examples that resemble the training data.\\n\\nKey features of generative AI include:\\n\\n1. **Content Creation**: It can generate diverse types of content, such as writing articles, creating artwork, composing music, and even producing realistic images or videos.\\n\\n2. **Models**: Common frameworks used in generative AI include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer models like GPT (Generative Pre-trained Transformer) that are particularly effective for text generation.\\n\\n3. **Training**: These models are trained on large datasets, learning the underlying patterns and structures, which they can then use to generate new instances that are coherent and contextually relevant.\\n\\n4. **Applications**: Generative AI has a wide range of applications, including content creation for marketing, game development, personalized media, simulation of real-world scenarios, and even in scientific research for drug discovery.\\n\\n5. **Ethical Considerations**: The rise of generative AI also raises important ethical questions, such as issues of copyright, misinformation, and the potential for role replacement in creative fields.\\n\\nOverall, generative AI represents a significant advancement in artificial intelligence, enabling machines to contribute creatively in ways that were previously thought to be the exclusive domain of humans.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 310, 'prompt_tokens': 13, 'total_tokens': 323, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1542007cca', 'id': 'chatcmpl-C5Pqh1kY7i8SLDLhTBZYyYGCmvu9U', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--afe4385d-52c6-42b9-906d-066e660d043b-0' usage_metadata={'input_tokens': 13, 'output_tokens': 310, 'total_tokens': 323, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "### Note: The above code assumes that the environment variables are set correctly in your .env file.\n",
    "# Input and get response\n",
    "response = llm.invoke(\"What is generative AI?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "313b7ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer . Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template\n",
    "## how we want our llm to behave , we set the rules\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer . Provide me answers based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d00cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a tool designed to assist developers in working with large language models (LLMs). It typically provides various features that enhance the development and deployment of machine learning models, particularly in natural language processing (NLP) tasks. Some of the key use cases and functionalities of Langsmith include:\\n\\n1. **Prompt Engineering**: Langsmith can help users create and refine prompts to get better responses from LLMs, thus improving the model's accuracy and relevance in generating outputs.\\n\\n2. **Testing and Validation**: It allows developers to test different prompts and validate the responses from the model, making it easier to iterate and improve the LLM's performance.\\n\\n3. **Workflow Management**: Langsmith can aid in organizing and managing the workflows associated with deploying and maintaining language models, streamlining the process.\\n\\n4. **Version Control**: Keeping track of different versions of prompts and outputs can be crucial for reproducibility. Langsmith may offer features for versioning prompts and their associated responses.\\n\\n5. **Integration with Other Tools**: Langsmith might integrate with various development environments and platforms to enhance the capabilities of existing tools used in AI and machine learning projects.\\n\\n6. **Analytics and Insights**: It can provide analytics on performance data, helping users understand how well their prompts are functioning and where they can make improvements.\\n\\nIn summary, Langsmith serves as a comprehensive tool for optimizing the interaction and performance of language models, facilitating more efficient model deployment and maintenance processes.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 294, 'prompt_tokens': 32, 'total_tokens': 326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C5Q6k8A4w42bH2czxBpKJxIWRxRgB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--92afce77-a33d-442e-a79e-dcf0e93db5f7-0' usage_metadata={'input_tokens': 32, 'output_tokens': 294, 'total_tokens': 326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# chain is used to combine the prompt and the LLM\n",
    "chain = prompt|llm # This creates a chain that combines the prompt and the LLM\n",
    "response = chain.invoke({\"input\": \"What is Langsmith useful for?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315b4a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0de7e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last knowledge update in October 2023, Langsmith is a tool designed for developers and teams working with machine learning and natural language processing (NLP) applications. It focuses on creating and managing language models more efficiently. Langsmith provides features such as:\n",
      "\n",
      "1. **Model Management**: It allows users to manage different versions of language models, making it easier to track changes and roll back to previous versions if necessary.\n",
      "\n",
      "2. **Data Annotation**: Langsmith often includes functionalities for annotating and preparing data, which is crucial for training robust language models.\n",
      "\n",
      "3. **Integration**: The tool is typically designed to integrate easily into existing workflows and systems, which can streamline the development process.\n",
      "\n",
      "4. **Collaboration**: It may provide features that facilitate collaboration among team members, enabling better communication and project management.\n",
      "\n",
      "5. **Performance Monitoring**: Langsmith likely offers tools for monitoring model performance and making improvements based on user feedback and analytics.\n",
      "\n",
      "Please verify with the latest resources or their official website for any updates or specific functionalities that may have been introduced after October 2023.\n"
     ]
    }
   ],
   "source": [
    "#stroutput parser - getting the string output from the response and displaying it\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser # This creates a chain that combines the prompt, LLM, and output parser\n",
    "response = chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
