{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf64133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed933261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001715F4CB8E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001715F4C93F0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\", groq_api_key = groq_api_key)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefc5c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's lovely to meet you, Snowfall! \\n\\nWhat can I do for you today? ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 14, 'total_tokens': 41, 'completion_time': 0.049090909, 'prompt_time': 0.001248299, 'queue_time': 0.24372749, 'total_time': 0.050339208}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ed768a2-24c0-47f5-bf2d-a62fa7951e99-0', usage_metadata={'input_tokens': 14, 'output_tokens': 27, 'total_tokens': 41})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response = model.invoke([HumanMessage(content = \"My name is Snowfall\")])\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a263329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Snowfall. ðŸ˜Š \\n\\nI remember! How can I help you further?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 52, 'total_tokens': 74, 'completion_time': 0.04, 'prompt_time': 0.001713798, 'queue_time': 0.248349431, 'total_time': 0.041713798}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--563235cb-4a3c-4a73-863f-19b4cd86343b-0', usage_metadata={'input_tokens': 52, 'output_tokens': 22, 'total_tokens': 74})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"My name is Snowfall\"),\n",
    "        AIMessage(content = \"Hello Snowfall, it's nice to meet you! \\n\\nIs there anything I can help you with today?\"),\n",
    "        HumanMessage(content = \"Whats my name?\")\n",
    "    ]\n",
    ") #this is actually acting as the conversational history\n",
    "# whether its able to remember the past history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af065a2",
   "metadata": {},
   "source": [
    "message history\n",
    "we can use a message history class to wrap our model and make it stateful, this will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a743c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id : str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() # object of this chatmessagehistory class\n",
    "    return store[session_id]  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172334bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\"configurable\" :{\n",
    "    \"session_id\":\" chat1\"\n",
    "}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06236108",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e35c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"My name is Snowfall\")],\n",
    "        config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef3b6ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Snowfall. ðŸ˜Š  \\n\\nI remember!  \\n\\nDo you have any other questions for me?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 53, 'total_tokens': 79, 'completion_time': 0.047272727, 'prompt_time': 0.001784851, 'queue_time': 0.250963839, 'total_time': 0.049057578}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--619d0143-3676-40bb-9629-3a09e0f24702-0', usage_metadata={'input_tokens': 53, 'output_tokens': 26, 'total_tokens': 79})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"What's my name?\")],\n",
    "        config = config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f2113c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Managing the conversation history\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 45,\n",
    "    strategy =\"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
