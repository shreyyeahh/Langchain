{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf64133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed933261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001CE489A8A90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001CE489A8490>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\", groq_api_key = groq_api_key)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefc5c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Snowfall, it's nice to meet you! \\n\\nIs there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 14, 'total_tokens': 41, 'completion_time': 0.049090909, 'prompt_time': 0.001247509, 'queue_time': 0.248452851, 'total_time': 0.050338418}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f51d9bb8-5d4e-4e66-a1e7-42b9b25e832f-0', usage_metadata={'input_tokens': 14, 'output_tokens': 27, 'total_tokens': 41})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response = model.invoke([HumanMessage(content = \"My name is Snowfall\")])\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a263329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Snowfall. ðŸ˜Š \\n\\nI remember!  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 52, 'total_tokens': 79, 'completion_time': 0.049090909, 'prompt_time': 0.001709328, 'queue_time': 0.247804352, 'total_time': 0.050800237}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f5df4187-d0c2-4533-9ea2-bd85a1afbf69-0', usage_metadata={'input_tokens': 52, 'output_tokens': 27, 'total_tokens': 79})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"My name is Snowfall\"),\n",
    "        AIMessage(content = \"Hello Snowfall, it's nice to meet you! \\n\\nIs there anything I can help you with today?\"),\n",
    "        HumanMessage(content = \"Whats my name?\")\n",
    "    ]\n",
    ") #this is actually acting as the conversational history\n",
    "# whether its able to remember the past history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af065a2",
   "metadata": {},
   "source": [
    "message history\n",
    "we can use a message history class to wrap our model and make it stateful, this will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id : str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() # object of this chatmessagehistory class\n",
    "    return store[session_id]  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
